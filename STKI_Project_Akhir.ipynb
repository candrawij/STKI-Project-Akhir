{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYm2gE73arRp",
        "outputId": "9dbf7681-0621-4eb3-87bc-54244b76f99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in c:\\users\\candra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\Candra\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install Sastrawi\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import math\n",
        "import sys\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Doc_ID         Nama_Tempat                 Lokasi  Rating  \\\n",
            "0       1  Kuncen Camp Ground  Kab. Semarang, Jateng       5   \n",
            "1       2  Kuncen Camp Ground  Kab. Semarang, Jateng       5   \n",
            "2       3  Kuncen Camp Ground  Kab. Semarang, Jateng       5   \n",
            "3       4  Kuncen Camp Ground  Kab. Semarang, Jateng       5   \n",
            "4       5  Kuncen Camp Ground  Kab. Semarang, Jateng       5   \n",
            "\n",
            "                                         Teks_Mentah  \n",
            "0  Bagus banget tempatnya, terkonsep dan guide ny...  \n",
            "1  Sangat menyenangkan untuk camping ceria.\\r\\nNy...  \n",
            "2  Tempatnya asri dan sejuk, sudah lumayan ramai ...  \n",
            "3  3 kali ke sini, sekali ikut acara, 2 kali biki...  \n",
            "4  Tempat yang cocok untuk acara kemah, kami kema...  \n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df_corpus = pd.read_csv('corpus_kemah_jateng_diy - Sheet3.csv')\n",
        "\n",
        "print(df_corpus.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "2jOUj7bsdfRh"
      },
      "outputs": [],
      "source": [
        "# Import Sastrawi\n",
        "try:\n",
        "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "except ImportError:\n",
        "    print(\"Warning: Sastrawi is not available. Using Dummy Stemmer.\")\n",
        "    class DummyStemmer:\n",
        "        def stem(self, text):\n",
        "            return text\n",
        "    class StemmerFactory:\n",
        "        def create_stemmer(self):\n",
        "            return DummyStemmer()\n",
        "\n",
        "# Safety for NLTK Stopwords      \n",
        "try:\n",
        "    from nltk.corpus import stopwords\n",
        "    stopwords_id = set(stopwords.words('indonesian')) \n",
        "except (LookupError, ImportError):\n",
        "    print(\"Warning: Indonesian stopwords failed to load. Using minimal manual list.\")\n",
        "    stopwords_id = {\"yang\", \"dan\", \"di\", \"ke\", \"adalah\", \"dengan\", \"saya\", \"ini\"}\n",
        "\n",
        "# Inisialisasi Tools\n",
        "stemmer = StemmerFactory().create_stemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definisi Pemegangan Frasa Kompleks\n",
        "def substitute_complex_phrases(text, phrase_map):\n",
        "    \"\"\"Mengganti frasa kompleks dengan single token sebelum tokenisasi.\"\"\"\n",
        "    # Pastikan substitusi dilakukan pada teks lowercase\n",
        "    text_lower = text.lower()\n",
        "    \n",
        "    for phrase, token in phrase_map.items():\n",
        "        # Lakukan penggantian frasa dalam teks\n",
        "        # Misalnya: \"dataran tinggi\" diganti menjadi \"datarantinggi\"\n",
        "        text_lower = text_lower.replace(phrase, token)\n",
        "        \n",
        "    return text_lower\n",
        "\n",
        "# PHRASE_MAP yang sudah didefinisikan\n",
        "PHRASE_MAP = {\n",
        "    # Geografis/Kondisi\n",
        "    'dataran tinggi': 'datarantinggi',\n",
        "    'dataran rendah': 'dataranrendah',\n",
        "    'air terjun': 'airterjun',\n",
        "\n",
        "    # Fasilitas\n",
        "    'kamar mandi': 'kamarmandi',\n",
        "    'tempat parkir': 'tempatparkir',\n",
        "    'warung makan': 'warungmakan',\n",
        "    'air bersih': 'airbersih',\n",
        "    'listrik tersedia': 'listriktersedia',\n",
        "    'akses jalan': 'aksesjalan',\n",
        "\n",
        "    # Gabungkan istilah penting yang sering dicari\n",
        "    'pemandangan indah': 'pemandanganindah',\n",
        "    'suasana tenang': 'suasanatenang',\n",
        "    'harga terjangkau': 'hargaterjangkau',\n",
        "    'mudah diakses': 'mudahdiakses',\n",
        "    'tempat kemah': 'tempatkemah',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definisi Pemetaan Region\n",
        "REGION_MAP = {\n",
        "    'jateng': 'jateng', 'jawa tengah': 'jateng', 'jawatengah': 'jateng',\n",
        "    'diy': 'diy', 'jogja': 'diy', 'yogyakarta': 'diy', 'jogjakarta': 'diy'\n",
        "}\n",
        "\n",
        "def detect_region_and_filter_query(query_text):\n",
        "    \"\"\"\n",
        "    Menganalisis query untuk menentukan apakah mengandung niat regional.\n",
        "    Mengembalikan query yang sudah difilter (tanpa kata regional) dan kode region.\n",
        "    \"\"\"\n",
        "    \n",
        "    query_text_lower = query_text.lower()\n",
        "    detected_region = None\n",
        "    \n",
        "    # Deteksi Region\n",
        "    for term, region in REGION_MAP.items():\n",
        "        if term in query_text_lower:\n",
        "            detected_region = region\n",
        "            query_text_lower = query_text_lower.replace(term, '') # Hapus kata regional\n",
        "            # Break setelah region pertama terdeteksi (asumsi hanya 1 region per query)\n",
        "            break \n",
        "            \n",
        "    # Rebuild Query tanpa kata regional (untuk VSM)\n",
        "    # Hapus spasi berlebihan dan filter token kosong\n",
        "    filtered_query_text = \" \".join([word for word in query_text_lower.split() if word])\n",
        "    \n",
        "    return filtered_query_text, detected_region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definisi Special Intent Map\n",
        "SPECIAL_INTENT_MAP = {\n",
        "    'semua tempat kemah': 'ALL', \n",
        "    'tempat kemah terbaik': 'RATING_TOP',\n",
        "    'tempat kemah dengan ranking tertinggi': 'RATING_TOP',\n",
        "    'tempat kemah terburuk': 'RATING_BOTTOM',\n",
        "    \n",
        "}\n",
        "\n",
        "def detect_intent(query_text):\n",
        "    \"\"\"\n",
        "    Menganalisis query untuk menentukan niat khusus (ALL/RATING).\n",
        "    Mengembalikan query VSM yang sudah bersih, dan special_intent.\n",
        "    \"\"\"\n",
        "    query_text_lower = query_text.lower()\n",
        "    detected_region = None\n",
        "    special_intent = None\n",
        "    \n",
        "    # 1. Deteksi Niat Khusus (ALL/RATING)\n",
        "    for term, intent in SPECIAL_INTENT_MAP.items():\n",
        "        if term in query_text_lower:\n",
        "            special_intent = intent\n",
        "            query_text_lower = query_text_lower.replace(term, '')\n",
        "            break\n",
        "            \n",
        "    # 3. Rebuild Query VSM\n",
        "    filtered_query_text = \" \".join([word for word in query_text_lower.split() if word])\n",
        "    \n",
        "    return filtered_query_text, special_intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2. DEFENISI FUNGSI HELPER & VSM CLASSES ---\n",
        "# Fungsi Pembersihan Karakter Spesial\n",
        "def remove_special_characters(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\" \n",
        "    regex = re.compile(r'[^a-zA-Z0-9\\s]')\n",
        "    return re.sub(regex, '', text)\n",
        "\n",
        "# Fungsi Proses Penuh (Preprocessing)\n",
        "def full_preprocessing(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "        \n",
        "    cleaned_text = remove_special_characters(text)\n",
        "    cleaned_text = re.sub(r'\\d', '', cleaned_text)\n",
        "\n",
        "    text_with_phrases = substitute_complex_phrases(cleaned_text, PHRASE_MAP)\n",
        "    \n",
        "    # Simple Tokenization (split by whitespace) & Lowercasing\n",
        "    words = text_with_phrases.lower().split()\n",
        "    \n",
        "    words = [w for w in words if w not in stopwords_id]\n",
        "    \n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in words]\n",
        "    \n",
        "    final_words = [w for w in stemmed_words if len(w) > 1]\n",
        "    return final_words\n",
        "\n",
        "# Inverted Index Classes\n",
        "class Node:\n",
        "    def __init__(self, docId, freq=None):\n",
        "        self.freq = freq # TF-IDF weight\n",
        "        self.doc = docId\n",
        "        self.nextval = None\n",
        "\n",
        "class SlinkedList:\n",
        "    def __init__(self, head=None):\n",
        "        self.head = head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3. APLIKASI PREPROCESSING & HITUNG DF & IDF (INDEXING PHASE 1) ---\n",
        "# Pastikan dataset sudah dimuat di df_corpus\n",
        "df_corpus['Teks_Mentah'] = df_corpus['Teks_Mentah'].fillna('')\n",
        "df_corpus['Clean_Tokens'] = df_corpus['Teks_Mentah'].apply(full_preprocessing)\n",
        "\n",
        "N = len(df_corpus)\n",
        "df_counts = {} # Document Frequency\n",
        "\n",
        "for tokens in df_corpus['Clean_Tokens']:\n",
        "    for word in set(tokens): \n",
        "        df_counts[word] = df_counts.get(word, 0) + 1\n",
        "\n",
        "idf_scores = {}\n",
        "for term, count in df_counts.items():\n",
        "    idf_scores[term] = math.log10(N / count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4. BUILDING THE INVERTED INDEX WITH TF-IDF (INDEXING PHASE 2) ---\n",
        "linked_list_data = {}\n",
        "unique_words_all = set(df_counts.keys())\n",
        "\n",
        "for word in unique_words_all:\n",
        "    linked_list_data[word] = SlinkedList()\n",
        "    linked_list_data[word].head = Node(docId=0, freq=None) \n",
        "\n",
        "for index, row in df_corpus.iterrows():\n",
        "    doc_id = row['Doc_ID']\n",
        "    tokens = row['Clean_Tokens']\n",
        "    \n",
        "    tf_in_doc = {}\n",
        "    for word in tokens:\n",
        "        tf_in_doc[word] = tf_in_doc.get(word, 0) + 1\n",
        "\n",
        "    for term, tf in tf_in_doc.items():\n",
        "        tfidf = tf * idf_scores[term]\n",
        "        \n",
        "        linked_list = linked_list_data[term].head\n",
        "        while linked_list.nextval is not None:\n",
        "            linked_list = linked_list.nextval\n",
        "        \n",
        "        linked_list.nextval = Node(docId=doc_id, freq=tfidf)\n",
        "\n",
        "# Mapping Doc ID to Name and Rating for final result\n",
        "df_metadata = df_corpus[['Doc_ID', 'Nama_Tempat', 'Lokasi', 'Rating']].copy()\n",
        "avg_rating_per_place = df_metadata.groupby('Nama_Tempat')['Rating'].mean().reset_index()\n",
        "avg_rating_per_place.rename(columns={'Rating': 'Avg_Rating'}, inplace=True)\n",
        "df_metadata = df_metadata.merge(avg_rating_per_place, on='Nama_Tempat', how='left')\n",
        "df_metadata.set_index('Doc_ID', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5. FUNGSI VSM RANKING MURNI ---\n",
        "def search_by_keyword(query_text, region=None):\n",
        "    \"\"\"\n",
        "    Melakukan pencarian VSM murni berdasarkan kata kunci (relevansi ulasan).\n",
        "    \"\"\"\n",
        "    \n",
        "    # Panggil deteksi region dan filter query\n",
        "    vsm_query_text, region_filter = detect_region_and_filter_query(query_text)\n",
        "    \n",
        "    # Jika query menjadi kosong setelah filter regional, gunakan kata kunci default\n",
        "    if not vsm_query_text or vsm_query_text.isspace():\n",
        "        vsm_query_text = \"camping\" # Gunakan kata kunci generik 'camping' jika query kosong\n",
        "    \n",
        "    # 1. Preprocessing Query\n",
        "    query_tokens = full_preprocessing(query_text)\n",
        "    \n",
        "    if not query_tokens:\n",
        "        return []\n",
        "    \n",
        "    # 2. Query Vectorization (TF-IDF)\n",
        "    query_tf = {}\n",
        "    for word in query_tokens:\n",
        "        query_tf[word] = query_tf.get(word, 0) + 1\n",
        "        \n",
        "    query_weights = {}\n",
        "    involved_docs = set()\n",
        "    \n",
        "    for term, tf in query_tf.items():\n",
        "        if term in idf_scores:\n",
        "            query_weights[term] = tf * idf_scores[term]\n",
        "            \n",
        "            # Collect all documents involved from the Index\n",
        "            current_node = linked_list_data[term].head.nextval\n",
        "            while current_node is not None:\n",
        "                involved_docs.add(current_node.doc)\n",
        "                current_node = current_node.nextval\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    if not involved_docs:\n",
        "        return []\n",
        "\n",
        "    # 3. Cosine Similarity (Dot Product Only)\n",
        "    doc_scores = {doc_id: 0 for doc_id in involved_docs}\n",
        "    \n",
        "    # Calculate DOT PRODUCT: Sum(W(t,d) * W(t,q))\n",
        "    for term, W_q in query_weights.items():\n",
        "        current_node = linked_list_data[term].head.nextval\n",
        "        while current_node is not None:\n",
        "            doc_id = current_node.doc\n",
        "            W_d = current_node.freq # TF-IDF weight W(t,d)\n",
        "            doc_scores[doc_id] += W_d * W_q\n",
        "            current_node = current_node.nextval\n",
        "            \n",
        "    # 4. Ranking Ulasan (Doc ID)\n",
        "    ranked_results_by_doc = sorted(doc_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    \n",
        "    # 5. Agregasi ke Nama Tempat (Mengambil ulasan paling relevan per tempat)\n",
        "    final_recommendations = []\n",
        "    unique_names = set()\n",
        "    \n",
        "    for doc_id, vsm_score in ranked_results_by_doc:\n",
        "        meta = df_metadata.loc[doc_id]\n",
        "        \n",
        "        # Filter berdasarkan region jika diminta (opsional)\n",
        "        if region_filter:\n",
        "            # Contoh: jika region_filter='diy', Lokasi harus mengandung 'DIY'/'Jogja'\n",
        "            # Kita bandingkan region filter dengan string Lokasi\n",
        "            if region_filter not in meta['Lokasi'].lower():\n",
        "                continue # Skip dokumen yang tidak sesuai region\n",
        "            \n",
        "        name = meta['Nama_Tempat']\n",
        "        \n",
        "        if name not in unique_names:\n",
        "            unique_names.add(name)\n",
        "            final_recommendations.append({\n",
        "                'name': name,\n",
        "                'location': meta['Lokasi'],\n",
        "                'avg_rating': meta['Avg_Rating'],\n",
        "                'top_vsm_score': vsm_score, # Skor VSM dari ulasan paling relevan\n",
        "            })\n",
        "            \n",
        "    return final_recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saCnwIJzdgGw",
        "outputId": "70cb9409-de33-4e15-ca2e-abb73596afbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mesin pencarian siap untuk query selanjutnya...\n",
            "\n",
            "--------------------------------------------------\n",
            "HASIL PENCARIAN untuk: 'tempat kemah terbaik di jawa tengah'\n",
            "Kata Kunci Diproses: ['tempatkemah', 'baik', 'jawa']\n",
            "--------------------------------------------------\n",
            "Rekomendasi Tempat Kemah (Diurutkan berdasarkan Relevansi Ulasan Tertinggi):\n",
            "1. Ratan Lurung Basecamp Gedongsongo\n",
            "   | Lokasi: Kab. Semarang, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.80\n",
            "   | Skor Relevansi (VSM Score): 11.2521\n",
            "2. Camping Umbul Sidomukti\n",
            "   | Lokasi: Kab. Semarang, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.60\n",
            "   | Skor Relevansi (VSM Score): 3.3140\n",
            "3. Camp Ground Bukit Sikunir\n",
            "   | Lokasi: Wonosobo, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.60\n",
            "   | Skor Relevansi (VSM Score): 1.6570\n",
            "4. Pinusan Nglimut\n",
            "   | Lokasi: Kendal, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.20\n",
            "   | Skor Relevansi (VSM Score): 1.6570\n",
            "5. Camp ground puncak ungaran\n",
            "   | Lokasi: Kab. Semarang, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.50\n",
            "   | Skor Relevansi (VSM Score): 1.6570\n",
            "\n",
            "Sesi pencarian diakhiri. Terima kasih!\n"
          ]
        }
      ],
      "source": [
        "print(\"==================================================\")\n",
        "print(\"MESIN PENCARIAN REKOMENDASI TEMPAT KEMAH VSM SIAP!\")\n",
        "print(\"==================================================\")\n",
        "print(\"Anda dapat memasukkan kata kunci untuk mencari rekomendasi.\")\n",
        "\n",
        "while True:\n",
        "    # Mengambil input query dari pengguna\n",
        "    query_text = input(\"\\nMasukkan kata kunci pencarian (atau ketik 'keluar' untuk berhenti): \\n\").strip()\n",
        "    \n",
        "    if query_text.lower() in ('keluar', 'exit', 'berhenti', 'quit', 'stop', 'kembali'):\n",
        "        print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "        break\n",
        "    \n",
        "    if not query_text:\n",
        "        continue\n",
        "        \n",
        "    # Panggil fungsi pencarian VSM\n",
        "    vsm_ranking = search_by_keyword(query_text, region=None) \n",
        "\n",
        "    # Deteksi region untuk ditampilkan\n",
        "    _, detected_region = detect_region_and_filter_query(query_text)\n",
        "    filter_status = f\"Filtered by: {detected_region.upper()}\" if detected_region else \"No Region Filter Applied\"\n",
        "    \n",
        "    print(\"\\n--------------------------------------------------\")\n",
        "    print(f\"HASIL PENCARIAN untuk: '{query_text}'\")\n",
        "    print(f\"Kata Kunci Diproses: {full_preprocessing(query_text)}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    if vsm_ranking:\n",
        "        print(\"Rekomendasi Tempat Kemah (Diurutkan berdasarkan Relevansi Ulasan Tertinggi):\")\n",
        "        \n",
        "        for i, item in enumerate(vsm_ranking):\n",
        "            print(f\"{i+1}. {item['name']}\")\n",
        "            print(f\"   | Lokasi: {item['location']}\")\n",
        "            print(f\"   | Rata-rata Rating Tempat: {item['avg_rating']:.2f}\")\n",
        "            print(f\"   | Skor Relevansi (VSM Score): {item['top_vsm_score']:.4f}\")\n",
        "        \n",
        "        # Logika lanjut\n",
        "        continue_input = input(\"\\nApakah Anda ingin melanjutkan pencarian? (ya/tidak): \").strip().lower()\n",
        "        \n",
        "        if continue_input not in ('ya', 'y'):\n",
        "            print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "            break\n",
        "            \n",
        "        # Hapus output sebelum loop selanjutnya\n",
        "        clear_output(wait=True) \n",
        "        print(\"Mesin pencarian siap untuk query selanjutnya...\")\n",
        "    else:\n",
        "        print(\"Tidak ditemukan tempat kemah yang relevan dengan kata kunci ini.\")\n",
        "        \n",
        "        # Logika lanjut\n",
        "        continue_input = input(\"\\nApakah Anda ingin melanjutkan pencarian? (ya/tidak): \").strip().lower()\n",
        "        \n",
        "        if continue_input not in ('ya', 'y'):\n",
        "            print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "            break\n",
        "            \n",
        "        # Hapus output sebelum loop selanjutnya\n",
        "        clear_output(wait=True) \n",
        "        print(\"Mesin pencarian siap untuk query selanjutnya...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
