{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYm2gE73arRp",
        "outputId": "9dbf7681-0621-4eb3-87bc-54244b76f99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Doc_ID         Nama_Tempat                 Lokasi  Rating  \\\n",
            "0       1  Kuncen Camp Ground  Kab. Semarang, Jateng     5.0   \n",
            "1       2  Kuncen Camp Ground  Kab. Semarang, Jateng     5.0   \n",
            "2       3  Kuncen Camp Ground  Kab. Semarang, Jateng     5.0   \n",
            "3       4  Kuncen Camp Ground  Kab. Semarang, Jateng     5.0   \n",
            "4       5  Kuncen Camp Ground  Kab. Semarang, Jateng     5.0   \n",
            "\n",
            "                                         Teks_Mentah  \n",
            "0  Bagus banget tempatnya, terkonsep dan guide ny...  \n",
            "1  Sangat menyenangkan untuk camping ceria.\\r\\nNy...  \n",
            "2  Tempatnya asri dan sejuk, sudah lumayan ramai ...  \n",
            "3  3 kali ke sini, sekali ikut acara, 2 kali biki...  \n",
            "4  Tempat yang cocok untuk acara kemah, kami kema...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_corpus = pd.read_csv('corpus_kemah_jateng_diy - Sheet2.csv')\n",
        "\n",
        "print(df_corpus.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in c:\\users\\candra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\Candra\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import math\n",
        "import sys\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2jOUj7bsdfRh"
      },
      "outputs": [],
      "source": [
        "# Import library untuk menghapus output di Colab/Jupyter\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# --- SAFETY CHECKS & DUMMY CLASSES FOR ENVIRONMENT ISSUES ---\n",
        "# Import Sastrawi (menggunakan dummy jika tidak tersedia)\n",
        "try:\n",
        "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "except ImportError:\n",
        "    print(\"Warning: Sastrawi is not available. Using Dummy Stemmer.\")\n",
        "    class DummyStemmer:\n",
        "        def stem(self, text):\n",
        "            return text\n",
        "    class StemmerFactory:\n",
        "        def create_stemmer(self):\n",
        "            return DummyStemmer()\n",
        "        \n",
        "# Safety for NLTK Stopwords\n",
        "try:\n",
        "    from nltk.corpus import stopwords\n",
        "    stopwords_id = set(stopwords.words('indonesian')) \n",
        "except (LookupError, ImportError):\n",
        "    print(\"Warning: Indonesian stopwords failed to load. Using minimal manual list.\")\n",
        "    stopwords_id = {\"yang\", \"dan\", \"di\", \"ke\", \"adalah\", \"dengan\", \"saya\", \"ini\"}\n",
        "\n",
        "# Inisialisasi Tools\n",
        "stemmer = StemmerFactory().create_stemmer()\n",
        "\n",
        "# --- 2. DEFENISI FUNGSI HELPER & VSM CLASSES ---\n",
        "# Fungsi Pembersihan Karakter Spesial\n",
        "def remove_special_characters(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\" \n",
        "    regex = re.compile(r'[^a-zA-Z0-9\\s]')\n",
        "    return re.sub(regex, '', text)\n",
        "\n",
        "# Fungsi Proses Penuh (Preprocessing)\n",
        "def full_preprocessing(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "        \n",
        "    cleaned_text = remove_special_characters(text)\n",
        "    cleaned_text = re.sub(r'\\d', '', cleaned_text)\n",
        "    \n",
        "    # Simple Tokenization (split by whitespace) & Lowercasing\n",
        "    words = cleaned_text.lower().split()\n",
        "    \n",
        "    words = [w for w in words if w not in stopwords_id]\n",
        "    \n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in words]\n",
        "    \n",
        "    final_words = [w for w in stemmed_words if len(w) > 1]\n",
        "    return final_words\n",
        "\n",
        "# Inverted Index Classes\n",
        "class Node:\n",
        "    def __init__(self, docId, freq=None):\n",
        "        self.freq = freq # TF-IDF weight\n",
        "        self.doc = docId\n",
        "        self.nextval = None\n",
        "\n",
        "class SlinkedList:\n",
        "    def __init__(self, head=None):\n",
        "        self.head = head\n",
        "\n",
        "\n",
        "# --- 3. APLIKASI PREPROCESSING & HITUNG DF & IDF (INDEXING PHASE 1) ---\n",
        "df_corpus = pd.read_csv('corpus_kemah_jateng_diy - Sheet1.csv')\n",
        "df_corpus['Teks_Mentah'] = df_corpus['Teks_Mentah'].fillna('')\n",
        "df_corpus['Clean_Tokens'] = df_corpus['Teks_Mentah'].apply(full_preprocessing)\n",
        "\n",
        "N = len(df_corpus)\n",
        "df_counts = {} # Document Frequency\n",
        "\n",
        "for tokens in df_corpus['Clean_Tokens']:\n",
        "    for word in set(tokens): \n",
        "        df_counts[word] = df_counts.get(word, 0) + 1\n",
        "\n",
        "idf_scores = {}\n",
        "for term, count in df_counts.items():\n",
        "    idf_scores[term] = math.log10(N / count)\n",
        "\n",
        "# --- 4. BUILDING THE INVERTED INDEX WITH TF-IDF (INDEXING PHASE 2) ---\n",
        "linked_list_data = {}\n",
        "unique_words_all = set(df_counts.keys())\n",
        "\n",
        "for word in unique_words_all:\n",
        "    linked_list_data[word] = SlinkedList()\n",
        "    linked_list_data[word].head = Node(docId=0, freq=None) \n",
        "\n",
        "for index, row in df_corpus.iterrows():\n",
        "    doc_id = row['Doc_ID']\n",
        "    tokens = row['Clean_Tokens']\n",
        "    \n",
        "    tf_in_doc = {}\n",
        "    for word in tokens:\n",
        "        tf_in_doc[word] = tf_in_doc.get(word, 0) + 1\n",
        "\n",
        "    for term, tf in tf_in_doc.items():\n",
        "        tfidf = tf * idf_scores[term]\n",
        "        \n",
        "        linked_list = linked_list_data[term].head\n",
        "        while linked_list.nextval is not None:\n",
        "            linked_list = linked_list.nextval\n",
        "        \n",
        "        linked_list.nextval = Node(docId=doc_id, freq=tfidf)\n",
        "\n",
        "# Mapping Doc ID to Name and Rating for final result\n",
        "df_metadata = df_corpus[['Doc_ID', 'Nama_Tempat', 'Lokasi', 'Rating']].copy()\n",
        "avg_rating_per_place = df_metadata.groupby('Nama_Tempat')['Rating'].mean().reset_index()\n",
        "avg_rating_per_place.rename(columns={'Rating': 'Avg_Rating'}, inplace=True)\n",
        "df_metadata = df_metadata.merge(avg_rating_per_place, on='Nama_Tempat', how='left')\n",
        "df_metadata.set_index('Doc_ID', inplace=True)\n",
        "\n",
        "\n",
        "# --- 5. FUNGSI VSM RANKING MURNI ---\n",
        "def search_by_keyword(query_text, region=None):\n",
        "    \"\"\"\n",
        "    Melakukan pencarian VSM murni berdasarkan kata kunci (relevansi ulasan).\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Preprocessing Query\n",
        "    query_tokens = full_preprocessing(query_text)\n",
        "    \n",
        "    if not query_tokens:\n",
        "        return []\n",
        "    \n",
        "    # 2. Query Vectorization (TF-IDF)\n",
        "    query_tf = {}\n",
        "    for word in query_tokens:\n",
        "        query_tf[word] = query_tf.get(word, 0) + 1\n",
        "        \n",
        "    query_weights = {}\n",
        "    involved_docs = set()\n",
        "    \n",
        "    for term, tf in query_tf.items():\n",
        "        if term in idf_scores:\n",
        "            query_weights[term] = tf * idf_scores[term]\n",
        "            \n",
        "            # Collect all documents involved from the Index\n",
        "            current_node = linked_list_data[term].head.nextval\n",
        "            while current_node is not None:\n",
        "                involved_docs.add(current_node.doc)\n",
        "                current_node = current_node.nextval\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    if not involved_docs:\n",
        "        return []\n",
        "\n",
        "    # 3. Cosine Similarity (Dot Product Only)\n",
        "    doc_scores = {doc_id: 0 for doc_id in involved_docs}\n",
        "    \n",
        "    # Calculate DOT PRODUCT: Sum(W(t,d) * W(t,q))\n",
        "    for term, W_q in query_weights.items():\n",
        "        current_node = linked_list_data[term].head.nextval\n",
        "        while current_node is not None:\n",
        "            doc_id = current_node.doc\n",
        "            W_d = current_node.freq # TF-IDF weight W(t,d)\n",
        "            doc_scores[doc_id] += W_d * W_q\n",
        "            current_node = current_node.nextval\n",
        "            \n",
        "    # 4. Ranking Ulasan (Doc ID)\n",
        "    ranked_results_by_doc = sorted(doc_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    \n",
        "    # 5. Agregasi ke Nama Tempat (Mengambil ulasan paling relevan per tempat)\n",
        "    final_recommendations = []\n",
        "    unique_names = set()\n",
        "    \n",
        "    for doc_id, vsm_score in ranked_results_by_doc:\n",
        "        meta = df_metadata.loc[doc_id]\n",
        "        \n",
        "        # Filter berdasarkan region jika diminta (opsional)\n",
        "        if region and region.lower() not in meta['Lokasi'].lower():\n",
        "            continue\n",
        "            \n",
        "        name = meta['Nama_Tempat']\n",
        "        \n",
        "        if name not in unique_names:\n",
        "            unique_names.add(name)\n",
        "            final_recommendations.append({\n",
        "                'name': name,\n",
        "                'location': meta['Lokasi'],\n",
        "                'avg_rating': meta['Avg_Rating'],\n",
        "                'top_vsm_score': vsm_score, # Skor VSM dari ulasan paling relevan\n",
        "            })\n",
        "            \n",
        "    return final_recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saCnwIJzdgGw",
        "outputId": "70cb9409-de33-4e15-ca2e-abb73596afbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mesin pencarian siap untuk query selanjutnya...\n",
            "\n",
            "--------------------------------------------------\n",
            "HASIL PENCARIAN untuk: 'dataran tinggi atau dekat gunung'\n",
            "Kata Kunci Diproses: ['datar', 'gunung']\n",
            "--------------------------------------------------\n",
            "Rekomendasi Tempat Kemah (Diurutkan berdasarkan Relevansi Ulasan Tertinggi):\n",
            "1. camp ground\n",
            "   | Lokasi: Gunungkidul, DIY\n",
            "   | Rata-rata Rating Tempat: 4.70\n",
            "   | Skor Relevansi (VSM Score): 2.8865\n",
            "2. Camping Umbul Sidomukti\n",
            "   | Lokasi: Kab. Semarang, Jateng\n",
            "   | Rata-rata Rating Tempat: 4.60\n",
            "   | Skor Relevansi (VSM Score): 1.4929\n",
            "\n",
            "Sesi pencarian diakhiri. Terima kasih!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==================================================\")\n",
        "print(\"MESIN PENCARIAN REKOMENDASI TEMPAT KEMAH VSM SIAP!\")\n",
        "print(\"==================================================\")\n",
        "print(\"Anda dapat memasukkan kata kunci untuk mencari rekomendasi.\")\n",
        "\n",
        "while True:\n",
        "    # Mengambil input query dari pengguna\n",
        "    query_text = input(\"\\nMasukkan kata kunci pencarian (atau ketik 'keluar' untuk berhenti): \").strip()\n",
        "    \n",
        "    if query_text.lower() in ('keluar', 'exit', 'berhenti', 'quit', 'stop', 'kembali'):\n",
        "        print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "        break\n",
        "    \n",
        "    if not query_text:\n",
        "        continue\n",
        "        \n",
        "    # Panggil fungsi pencarian VSM\n",
        "    vsm_ranking = search_by_keyword(query_text, region=None) \n",
        "    \n",
        "    print(\"\\n--------------------------------------------------\")\n",
        "    print(f\"HASIL PENCARIAN untuk: '{query_text}'\")\n",
        "    print(f\"Kata Kunci Diproses: {full_preprocessing(query_text)}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    if vsm_ranking:\n",
        "        print(\"Rekomendasi Tempat Kemah (Diurutkan berdasarkan Relevansi Ulasan Tertinggi):\")\n",
        "        \n",
        "        # Menampilkan 5 hasil teratas\n",
        "        for i, item in enumerate(vsm_ranking[:5]):\n",
        "            print(f\"{i+1}. {item['name']}\")\n",
        "            print(f\"   | Lokasi: {item['location']}\")\n",
        "            print(f\"   | Rata-rata Rating Tempat: {item['avg_rating']:.2f}\")\n",
        "            print(f\"   | Skor Relevansi (VSM Score): {item['top_vsm_score']:.4f}\")\n",
        "        \n",
        "        # --- LOGIKA TAMBAHAN: TANYA LANJUT ---\n",
        "        continue_input = input(\"\\nApakah Anda ingin melanjutkan pencarian? (ya/tidak): \").strip().lower()\n",
        "        \n",
        "        if continue_input not in ('ya', 'y'):\n",
        "            print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "            break\n",
        "            \n",
        "        # Hapus output sebelum loop selanjutnya\n",
        "        clear_output(wait=True) \n",
        "        print(\"Mesin pencarian siap untuk query selanjutnya...\")\n",
        "    else:\n",
        "        print(\"Tidak ditemukan tempat kemah yang relevan dengan kata kunci ini.\")\n",
        "        \n",
        "        # --- LOGIKA TAMBAHAN: TANYA LANJUT ---\n",
        "        continue_input = input(\"\\nApakah Anda ingin melanjutkan pencarian? (ya/tidak): \").strip().lower()\n",
        "        \n",
        "        if continue_input not in ('ya', 'y'):\n",
        "            print(\"\\nSesi pencarian diakhiri. Terima kasih!\")\n",
        "            break\n",
        "            \n",
        "        # Hapus output sebelum loop selanjutnya\n",
        "        clear_output(wait=True) \n",
        "        print(\"Mesin pencarian siap untuk query selanjutnya...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
